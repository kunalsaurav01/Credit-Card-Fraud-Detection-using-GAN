ğŸ’³ Credit Card Fraud Detection using GAN

This project addresses the extreme class imbalance problem in credit card fraud detection by using a Generative Adversarial Network (GAN) to generate realistic synthetic fraud transactions.
Instead of duplicating rare fraud samples (like SMOTE), the GAN learns the true fraud distribution and generates high-quality synthetic data.

ğŸš€ Project Motivation

Credit card fraud datasets are highly imbalanced:

Legitimate transactions â‰ˆ 99.8%

Fraud transactions â‰ˆ 0.2%

Traditional classifiers become biased toward the majority class.
This project uses GANs to:

Learn fraud transaction patterns

Generate realistic synthetic fraud samples

Improve downstream fraud detection performance

ğŸ§  Key Concept

GANs generate new fraud samples instead of copying existing ones, reducing overfitting and improving generalization.

ğŸ› ï¸ Tech Stack

Python

TensorFlow / Keras

NumPy

Pandas

Scikit-learn

Matplotlib

ğŸ“‚ Dataset

Dataset: creditcard.csv

Source: Kaggle â€“ Credit Card Fraud Detection Dataset

Target Column: Class

0 â†’ Normal transaction

1 â†’ Fraud transaction

ğŸ§ª Workflow

Load and preprocess data

Separate fraud and normal transactions

Scale fraud features using StandardScaler

Train GAN only on fraud data

Generate synthetic fraud samples

Combine synthetic fraud with real data

Create a balanced dataset for classification

ğŸ—ï¸ GAN Architecture
Generator

Dense(256) â†’ LeakyReLU â†’ BatchNorm

Dense(128) â†’ LeakyReLU â†’ BatchNorm

Dense(input_dim) â†’ tanh

Discriminator

Dense(256) â†’ LeakyReLU â†’ Dropout

Dense(128) â†’ LeakyReLU â†’ Dropout

Dense(1) â†’ sigmoid

âš™ï¸ Training Details

Loss Function: Binary Cross-Entropy

Optimizers: Adam

Label Smoothing: Applied

Training Type: Custom training loop

Epochs: 10,000 (early stopping enabled)

ğŸ“Š Sample Training Output
Epoch 0     | D Loss: 8.92 | G Loss: 0.70
Epoch 1000  | D Loss: 1.91 | G Loss: 0.99
Epoch 5000  | D Loss: 1.78 | G Loss: 0.93
Epoch 9000  | D Loss: 1.49 | G Loss: 0.97


âœ” Indicates stable GAN convergence

ğŸ“ˆ Output

Synthetic fraud transactions generated

Balanced dataset created

Ready for training fraud detection classifiers (Logistic Regression, XGBoost, Neural Networks, etc.)

â–¶ï¸ How to Run
1ï¸âƒ£ Install dependencies
pip install tensorflow pandas numpy scikit-learn matplotlib

2ï¸âƒ£ Place dataset
project/
â”‚â”€â”€ creditcard.csv
â”‚â”€â”€ fraud_gan.ipynb
â”‚â”€â”€ README.md

3ï¸âƒ£ Run Jupyter Notebook
jupyter notebook


Open and run all cells in fraud_gan.ipynb.

ğŸ“Œ Results & Benefits

âœ” Handles extreme class imbalance
âœ” Generates realistic fraud patterns
âœ” Reduces overfitting
âœ” Better than SMOTE for complex fraud distributions

âš ï¸ Limitations

GAN training is computationally expensive

Generated samples should be validated statistically

Requires downstream classifier evaluation (ROC-AUC, PR-AUC)